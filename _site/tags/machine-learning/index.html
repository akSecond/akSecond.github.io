<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>Andrew Kornberg</title>
  <meta name="description" content="Hi, I'm Kornberg, a wild programmer & PhD. candidate">
  <meta name="author" content="Wei Wang">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Andrew Kornberg">
  <meta name="twitter:description" content="Hi, I'm Kornberg, a wild programmer & PhD. candidate">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Andrew Kornberg">
  <meta property="og:description" content="Hi, I'm Kornberg, a wild programmer & PhD. candidate">
  
  <link rel="icon" type="image/png" href="/assets/images/favicon.png" />
  <link href="/assets/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="http://kornbergfresnel.github.io/tags/machine-learning/">
  <link rel="alternate" type="application/rss+xml" title="Andrew Kornberg" href="http://kornbergfresnel.github.io/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>  
  
</head>




  <body>
    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>
    <header class="panel-cover " style="background-image: url('/assets/images/background-cover.jpg'); max-width: 700px; width: 30%;">
        <div class="panel-main">
      
          <div class="panel-main__inner panel-inverted">
          <div class="panel-main__content">
      
              <a href="/#blog" title="前往 Andrew Kornberg 的主页" class="blog-button"><img src="/assets/images/avatar.jpg" width="80" alt="Andrew Kornberg logo" class="panel-cover__logo logo" /></a>
              <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for Andrew Kornberg" class="blog-button">Andrew Kornberg</a></h1>
              
              <span class="panel-cover__subtitle panel-subtitle">abeunt studia in morse</span>
              
              <hr class="panel-cover__divider" />
              <p class="panel-cover__description">Hi, I'm Kornberg, a wild programmer & PhD. candidate</p>
              <hr class="panel-cover__divider panel-cover__divider--secondary" />
              
              
              
              <div class="navigation-wrapper">
                <div>
                  <nav class="cover-navigation cover-navigation--primary">
                    <ul class="navigation">
                      <li class="navigation__item"><a href="/#blog" title="Visit blog" class="blog-button">Blog</a></li>
                      
                        <li class="navigation__item"><a href="http://kornbergfresnel.github.io" target="_blank" title="My open-source projects">Projects</a></li>
                      
                    </ul>
                  </nav>
                </div>
                
                <div><nav class="cover-navigation navigation--social">
  <ul class="navigation">

  
  <!-- Weibo -->
  <li class="navigation__item">
    <a href="http://weibo.com/u/5104230793" title="@u/5104230793 的微博" target="_blank">
      <i class='social fa fa-weibo'></i>
      <span class="label">Weibo</span>
    </a>
  </li>
  

  
  <!-- Github -->
  <li class="navigation__item">
    <a href="https://github.com/KornbergFresnel" title="@KornbergFresnel 的 Github" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>
  
  
  
  <!-- Twitter -->
  <li class="navigation__item">
    <a href="http://twitter.com/andrew_kornberg" title="@andrew_kornberg" target="_blank">
      <i class='social fa fa-twitter'></i>
      <span class="label">Twitter</span>
    </a>
  </li>
  

  
  <!-- Google Plus -->
  <li class="navigation__item">
    <a href="https://plus.google.com/107108267983477358170" rel="author" title="Google+" target="_blank">
      <i class='social fa fa-google-plus-square'></i>
      <span class="label">Google Plus</span>
    </a>
  </li>
  

  <!-- RSS -->
  <li class="navigation__item">
    <a href="/feed.xml" rel="author" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>

  
  <!-- Email -->
  <li class="navigation__item">
    <a href="mailto:kornbergfresnel@outlook.com" title="Contact me">
      <i class='social fa fa-envelope'></i>
      <span class="label">Email</span>
    </a>
  </li>
  

  </ul>
</nav>
</div>
              </div>
            </div>
          </div>
          
          
            <div class="panel-cover--overlay cover-blue"></div>
          
        </div>
    </header>
    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <p style="border-bottom: 1px solid; padding-bottom: 5px">Articles by tag :<i class="fa fa-tag"></i> <a href="/tags/machine-learning/">Machine Learning</a></p>
            <div class="main-post-list">
                
                    <ol class="post-list">
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/11/Prove-of-Double-Q-learning/" title="访问 Prove of Double Q-learning">Prove of Double Q-learning</a></h2>
                                <p class="excerpt">In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is i...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-11-14 00:20:00 +0800" class="post-list__meta--date date">2017-11-14</time><a class="btn-border-small" href=/2017/11/Prove-of-Double-Q-learning/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/11/Temporal-Difference-Learning/" title="访问 Temporal-Difference Learning">Temporal-Difference Learning</a></h2>
                                <p class="excerpt">TD learning是对Monte Carlo和DP算法的综合，像Monte Carlo一样属于一种Modle Free算法，即不需要对环境模型有一个具体的认识（比如需要知道状态转移的Markov决策过程）；同时也像DP一样属于一种迭代更新算法。也许这个表达式可以更容易地帮助理解：其中 $V(S_t)$ 表示在 $t$ 时刻状态为 $S$ 的 state value，在Monte Carlo里面，$V(S)$ 的估计通常采用 first visit 进行，以保证估计过程的 unbias ...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-11-03 02:00:00 +0800" class="post-list__meta--date date">2017-11-03</time><a class="btn-border-small" href=/2017/11/Temporal-Difference-Learning/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/10/Some-Algorithms-For-MARL/" title="访问 Some Algorithms For MARL">Some Algorithms For MARL</a></h2>
                                <p class="excerpt">Deep Repeated Update Q-NetworkIt tries to address an issue in the way Q-learning estimate the value of an action. Ideally, if an agent could execute every possible action in parallel but identical environments at each time step, then information a...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-10-27 19:15:00 +0800" class="post-list__meta--date date">2017-10-27</time><a class="btn-border-small" href=/2017/10/Some-Algorithms-For-MARL/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/10/Monte-Carlo-Methods/" title="访问 Monte Carlo Methods">Monte Carlo Methods</a></h2>
                                <p class="excerpt">Off-policy Prediction via Importance SamplingTo be continued…Off-policy Monte Carlo ControlIn off-policy method, estimating the value of a policy and controling are separated, it is the mainly difference between on-policy and off-policy. In off-po...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-10-27 12:10:00 +0800" class="post-list__meta--date date">2017-10-27</time><a class="btn-border-small" href=/2017/10/Monte-Carlo-Methods/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/10/Multi-Step-Bootstrapping/" title="访问 Multi-Step Boostrapping">Multi-Step Boostrapping</a></h2>
                                <p class="excerpt">N-Step TD PredictionAn important property of n-step returns is that their expectation is guranteed to be a better estimate of $v_{\pi}$ than $V_{t+n-1}$ is, in a worst-state sense. That is, the worst error of the expected n-step return is guarante...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-10-23 13:45:00 +0800" class="post-list__meta--date date">2017-10-23</time><a class="btn-border-small" href=/2017/10/Multi-Step-Bootstrapping/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/10/Multi-armed-Bandits/" title="访问 Multi-armed Bandits">Multi-armed Bandits</a></h2>
                                <p class="excerpt">  将强化学习和其他学习方式区分开来的一个重要特征是：RL通过评估选取动作而不是指导agent应该执行哪些正确的动作，但其实将这两种方式融合在一起也是很有趣的。$k$-armed Bandit问题比如你需要在 $k$ 个不同的action中重复做出选择，在每个action决定作出后，你都会得到服从固定概率分布的reward，你的目标是最大化整个学习过程中的reward。为了方便后面的描述，我们做出如下定义：  $A_t$: the action selected on time step ...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-10-07 22:44:00 +0800" class="post-list__meta--date date">2017-10-07</time><a class="btn-border-small" href=/2017/10/Multi-armed-Bandits/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/10/%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/" title="访问 关于强化学习的一些简单介绍">关于强化学习的一些简单介绍</a></h2>
                                <p class="excerpt">什么是强化学习强化学习是非监督学习的一种，我们可以结合下面这个事实例子来理解，它涉及到这么几个子问题：如何做——如何将情境映射到动作——以便最大化数字化的奖励信号。其实从上面列出的三个子问题，我们可以进一步说明强化学习其实是一个闭环问题，因为学习系统的行为将来又会影响到后面（下一轮学习）的输入此外，学习系统中的“学习者”没有被告知应该采取哪种动作来到达下一状态，而是通过reward的反馈形式来尝试哪些动作或者行为能够让其获得更多的reward。这样的学习机制也反映出强化学习其实是异步的，或...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-10-03 20:58:00 +0800" class="post-list__meta--date date">2017-10-03</time><a class="btn-border-small" href=/2017/10/%E5%85%B3%E4%BA%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/10/LSTM-Tutorial/" title="访问 LSTM Tutorial">LSTM Tutorial</a></h2>
                                <p class="excerpt">  the LSTM network includes a set of recurrently connected subnets, which we call as “memory block”, these memory block are made with one or more self-conncted memory cells and three multiplicative units—the input, output, and forget gates—that pr...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-10-02 16:41:00 +0800" class="post-list__meta--date date">2017-10-02</time><a class="btn-border-small" href=/2017/10/LSTM-Tutorial/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                            <li>
                                <h2 class="post-list__post-title post-title"><a href="/2017/08/Lagrange-Multiplier%E5%92%8CKKT%E6%9D%A1%E4%BB%B6%E7%9A%84%E7%90%86%E8%A7%A3/" title="访问 Lagrange Multiplier和KKT条件的理解">Lagrange Multiplier和KKT条件的理解</a></h2>
                                <p class="excerpt">拉格朗日乘数法和KKT条件在凸优化问题中的作用很大，当目标函数属于凸函数问题时，使用这两种方法能够有效且简单的得到最优值。当然，两种方法也不是万能的，建立在数学上成立的算法应用到实际还是需要考虑机器效率，SVM使用KKT添加得到 $\alpha$ 集合条件但还需要使用SMO算法优化。凸优化问题的分类  在求解凸优化问题过程中，一个关键的想法是所有的局部最优都是全局最优      线性规划（Linear Programming）：如果优化问题的目标函数 $f$ 和以及不等式约束 $g_i$ ...&hellip;</p>
                                <div class="post-list__meta"><time datetime="2017-08-17 18:55:00 +0800" class="post-list__meta--date date">2017-08-17</time><a class="btn-border-small" href=/2017/08/Lagrange-Multiplier%E5%92%8CKKT%E6%9D%A1%E4%BB%B6%E7%9A%84%E7%90%86%E8%A7%A3/>继续阅读</a></div>
                                <hr class="post-list__divider" />
                            </li>
                        
                    </ol>
                
            </div>

            <section class="footer">
    <footer>
    	<span class="footer__copyright">本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享 署名-非商业性使用-相同方式共享 4.0 国际 许可协议</a></span>
        <span class="footer__copyright">由 <a href="https://jekyllrb.com">Jekyll</a> 于 2018-01-06 生成，感谢 <a href="https://www.digitalocean.com/?refcode=30ed2d146762">Digital Ocean</a> 为本站提供稳定的 VPS 服务</span>
        <span class="footer__copyright">本站由 <a href="http://twitter/andrew_kornberg">@andrew_kornberg</a> 创建，采用 <a href="https://github.com/onevcat/vno-jekyll">Vno - Jekyll</a> 作为主题，您可以在 GitHub 找到<a href="https://github.com/onevcat/OneV-s-Den">本站源码</a> - &copy; 2018</span>
    </footer>
</section>


            <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>

<script type="text/javascript" src="/js/main.js"></script>



                
        </div>
    </div>
  </body>
</html>
