<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <title>Andrew Kornberg</title>
  <meta name="description" content="Hi, I'm Kornberg, a wild programmer & PhD. candidate">
  <meta name="author" content="Wei Wang">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Andrew Kornberg">
  <meta name="twitter:description" content="Hi, I'm Kornberg, a wild programmer & PhD. candidate">
  
  <meta property="og:type" content="article">
  <meta property="og:title" content="Andrew Kornberg">
  <meta property="og:description" content="Hi, I'm Kornberg, a wild programmer & PhD. candidate">
  
  <link rel="icon" type="image/png" href="/assets/images/favicon.png" />
  <link href="/assets/images/favicon.png" rel="shortcut icon" type="image/png">
  
  <link rel="stylesheet" href="/css/main.css">
  <link href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="canonical" href="http://kornbergfresnel.github.io/">
  <link rel="alternate" type="application/rss+xml" title="Andrew Kornberg" href="http://kornbergfresnel.github.io/feed.xml">
  
  <meta name="google-site-verification" content="1-1ZlHoRvM0T2FqPbW2S-qLgYXN6rsn52kErlMPd_gw" />

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        inlineMath: [['$','$']]
      }
    });
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>  
  
</head>


  <body>

    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>
    
    <header class="panel-cover " style="background-image: url('/assets/images/background-cover.jpg')">
  <div class="panel-main">

    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/#blog" title="前往 Andrew Kornberg 的主页" class="blog-button"><img src="/assets/images/avatar.jpg" width="80" alt="Andrew Kornberg logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/#blog" title="link to homepage for Andrew Kornberg" class="blog-button">Andrew Kornberg</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">abeunt studia in morse</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">Hi, I'm Kornberg, a wild programmer & PhD. candidate</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />
        
        
        
        <div class="navigation-wrapper">
          <div>
            <nav class="cover-navigation cover-navigation--primary">
              <ul class="navigation">
                <li class="navigation__item"><a href="/#blog" title="Visit blog" class="blog-button">Blog</a></li>
                
                  <li class="navigation__item"><a href="http://kornbergfresnel.github.io" target="_blank" title="My open-source projects">Projects</a></li>
                
              </ul>
            </nav>
          </div>
          
          <div><nav class="cover-navigation navigation--social">
  <ul class="navigation">

  
  <!-- Weibo -->
  <li class="navigation__item">
    <a href="http://weibo.com/u/5104230793" title="@u/5104230793 的微博" target="_blank">
      <i class='social fa fa-weibo'></i>
      <span class="label">Weibo</span>
    </a>
  </li>
  

  
  <!-- Github -->
  <li class="navigation__item">
    <a href="https://github.com/KornbergFresnel" title="@KornbergFresnel 的 Github" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>
  
  
  
  <!-- Twitter -->
  <li class="navigation__item">
    <a href="http://twitter.com/andrew_kornberg" title="@andrew_kornberg" target="_blank">
      <i class='social fa fa-twitter'></i>
      <span class="label">Twitter</span>
    </a>
  </li>
  

  
  <!-- Google Plus -->
  <li class="navigation__item">
    <a href="https://plus.google.com/107108267983477358170" rel="author" title="Google+" target="_blank">
      <i class='social fa fa-google-plus-square'></i>
      <span class="label">Google Plus</span>
    </a>
  </li>
  

  <!-- RSS -->
  <li class="navigation__item">
    <a href="/feed.xml" rel="author" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>

  
  <!-- Email -->
  <li class="navigation__item">
    <a href="mailto:kornbergfresnel@outlook.com" title="Contact me">
      <i class='social fa fa-envelope'></i>
      <span class="label">Email</span>
    </a>
  </li>
  

  </ul>
</nav>
</div>
        </div>
      </div>
    </div>
    
    
    <div class="panel-cover--overlay cover-blue"></div>
    
  </div>
</header>


    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            

<div class="main-post-list hidden">

  <ol class="post-list">
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/12/Multi-Agent-Actor-Critic-For-Mixed-Cooperative-Competitive-Environments/" title="访问 Multi-Agent Actor-Critic For Mixed Cooperative-Competitive Environments">Multi-Agent Actor-Critic For Mixed Cooperative-Competitive Environments</a></h2>
      <p class="excerpt">Why propose this framework for Multi-Agent ?  Q-learning is not effective under non-stationary environment  policy-gradient suffers from a variance that increase as the number of agents grows  at this paper, authors proposal an adaptation of actor...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-12-19 00:00:00 +0800" class="post-list__meta--date date">2017-12-19</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/12/Multi-Agent-Actor-Critic-For-Mixed-Cooperative-Competitive-Environments/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/12/Analysis-Fictitious-Self-Play-in-Extensive-Form/" title="访问 Analysis - Fictitious Self-Play in Extensive-Form Games">Analysis - Fictitious Self-Play in Extensive-Form Games</a></h2>
      <p class="excerpt">这是Deep Mind于2015年发表在JMLR上的一篇文章，文章提出了fictitious play的两种变体方法，使得fictious play能够在大型问题中得到有效的应用。这两种方法在文中分别被称为Full-width extensive-form play（XFP）和Fictitious self-play（FSP）。其实现都是基于行为策略，使用这种策略的一个好处是，可以极大的减少需要参考的动作空间和状态数量，从而减轻模拟过程或者算法对计算资源的消耗，学习速率当然也会有提升。De...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-12-17 00:00:00 +0800" class="post-list__meta--date date">2017-12-17</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/12/Analysis-Fictitious-Self-Play-in-Extensive-Form/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/12/Overview-Multi-Agent/" title="访问 Overview - Multi-Agent">Overview - Multi-Agent</a></h2>
      <p class="excerpt">1. Multi-Agent reinforcement learning algorithms  keep tracking of the other agents’ policy for adaptation. (opponent modeling)  a fusion of temporal-different RL, game theory, and more general direct policy search techniques2. Fully cooperative t...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-12-14 15:35:00 +0800" class="post-list__meta--date date">2017-12-14</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/12/Overview-Multi-Agent/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/11/Prove-of-Double-Q-learning/" title="访问 Prove of Double Q-learning">Prove of Double Q-learning</a></h2>
      <p class="excerpt">In some stochastic environments the well-known reinforcement learning algorithm Q-learning performs very poorly. This poor performance is caused by large overestimations of action values. These overestimations result from a positive bias that is i...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-11-14 00:20:00 +0800" class="post-list__meta--date date">2017-11-14</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/11/Prove-of-Double-Q-learning/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/11/Temporal-Difference-Learning/" title="访问 Temporal-Difference Learning">Temporal-Difference Learning</a></h2>
      <p class="excerpt">TD learning是对Monte Carlo和DP算法的综合，像Monte Carlo一样属于一种Modle Free算法，即不需要对环境模型有一个具体的认识（比如需要知道状态转移的Markov决策过程）；同时也像DP一样属于一种迭代更新算法。也许这个表达式可以更容易地帮助理解：其中 $V(S_t)$ 表示在 $t$ 时刻状态为 $S$ 的 state value，在Monte Carlo里面，$V(S)$ 的估计通常采用 first visit 进行，以保证估计过程的 unbias ...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-11-03 02:00:00 +0800" class="post-list__meta--date date">2017-11-03</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/11/Temporal-Difference-Learning/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/11/SILENCE/" title="访问 SILENCE">SILENCE</a></h2>
      <p class="excerpt">​​Yeah, I'd rather be a lover than a fighter​Cause all my life, I've been fighting​Never felt a feeling of comfort​All this time, I've been hiding ​And I never had someone to call my own, oh nah​I'm so used to sharing​Love only left me alone​But I...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-11-02 23:30:00 +0800" class="post-list__meta--date date">2017-11-02</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/11/SILENCE/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/10/Some-Algorithms-For-MARL/" title="访问 Some Algorithms For MARL">Some Algorithms For MARL</a></h2>
      <p class="excerpt">Deep Repeated Update Q-NetworkIt tries to address an issue in the way Q-learning estimate the value of an action. Ideally, if an agent could execute every possible action in parallel but identical environments at each time step, then information a...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-10-27 19:15:00 +0800" class="post-list__meta--date date">2017-10-27</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/10/Some-Algorithms-For-MARL/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/10/Monte-Carlo-Methods/" title="访问 Monte Carlo Methods">Monte Carlo Methods</a></h2>
      <p class="excerpt">Off-policy Prediction via Importance SamplingTo be continued…Off-policy Monte Carlo ControlIn off-policy method, estimating the value of a policy and controling are separated, it is the mainly difference between on-policy and off-policy. In off-po...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-10-27 12:10:00 +0800" class="post-list__meta--date date">2017-10-27</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/10/Monte-Carlo-Methods/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/10/Multi-Step-Bootstrapping/" title="访问 Multi-Step Boostrapping">Multi-Step Boostrapping</a></h2>
      <p class="excerpt">N-Step TD PredictionAn important property of n-step returns is that their expectation is guranteed to be a better estimate of $v_{\pi}$ than $V_{t+n-1}$ is, in a worst-state sense. That is, the worst error of the expected n-step return is guarante...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-10-23 13:45:00 +0800" class="post-list__meta--date date">2017-10-23</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/10/Multi-Step-Bootstrapping/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
    <li>
      <h2 class="post-list__post-title post-title"><a href="/2017/10/Multi-armed-Bandits/" title="访问 Multi-armed Bandits">Multi-armed Bandits</a></h2>
      <p class="excerpt">  将强化学习和其他学习方式区分开来的一个重要特征是：RL通过评估选取动作而不是指导agent应该执行哪些正确的动作，但其实将这两种方式融合在一起也是很有趣的。$k$-armed Bandit问题比如你需要在 $k$ 个不同的action中重复做出选择，在每个action决定作出后，你都会得到服从固定概率分布的reward，你的目标是最大化整个学习过程中的reward。为了方便后面的描述，我们做出如下定义：  $A_t$: the action selected on time step ...&hellip;</p>
      <div class="post-list__meta"><time datetime="2017-10-07 22:44:00 +0800" class="post-list__meta--date date">2017-10-07</time> &#8226; <span class="post-list__meta--tags tags"></span><a class="btn-border-small" href=/2017/10/Multi-armed-Bandits/>继续阅读</a></div>
      <hr class="post-list__divider" />
    </li>
    
  </ol>

  <hr class="post-list__divider " />

<nav class="pagination" role="navigation">
    
    <span class="pagination__page-number">1 / 2</span>
    
        <a class="older-posts pagination__older btn btn-small btn-tertiary" href="/page/2/#blog">更早 &rarr;</a>
    
</nav>


</div>

            <section class="footer">
    <footer>
    	<span class="footer__copyright">本站点采用<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享 署名-非商业性使用-相同方式共享 4.0 国际 许可协议</a></span>
        <span class="footer__copyright">由 <a href="https://jekyllrb.com">Jekyll</a> 于 2018-01-06 生成，感谢 <a href="https://www.digitalocean.com/?refcode=30ed2d146762">Digital Ocean</a> 为本站提供稳定的 VPS 服务</span>
        <span class="footer__copyright">本站由 <a href="http://twitter/andrew_kornberg">@andrew_kornberg</a> 创建，采用 <a href="https://github.com/onevcat/vno-jekyll">Vno - Jekyll</a> 作为主题，您可以在 GitHub 找到<a href="https://github.com/onevcat/OneV-s-Den">本站源码</a> - &copy; 2018</span>
    </footer>
</section>

        </div>
    </div>
    
    <script type="text/javascript" src="//code.jquery.com/jquery-1.11.3.min.js"></script>

<script type="text/javascript" src="/js/main.js"></script>



    
  </body>

</html>
